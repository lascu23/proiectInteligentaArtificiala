# Artificial Intelligence: Predict the correct dialect of a text based on its translation in different languages
  Proiectul a constat în a antrena un clasificator pentru a prezice dialectul(engleză, irlandeză sau scoțiană) bazat pe traducerea unui text în diferite limbi(daneză, germană, italiană, olandeză și spaniolă). Datele de antrenare constă într-o colecție de 41570 de texte.
  Pentru început am citit datele de test și de antrenare. Codificăm etichetele în valori numerice, cele 3 etichete iau valori de la 0 la 2. Apoi, transformăm fiecare etichetă în valoarea ei numerică.
  Reținem seturi de cuvinte des folosite din fiecare limbă, pentru a putea mai târziu să le
eliminăm din texte.
  Funcția “proceseaza” simplifică textul, adică, textul initial va fi reprezentat ca o listă de cuvinte(tokens). În primul rând, scăpăm de toate semnele de punctuație, deoarece ele sunt aceleași în fiecare limbă. Mai departe, transformăm caracterul “\n” într-un spațiu gol, iar apoi eliminăm și toate spațiile goale. Facem toate cuvintele sa înceapă cu literă mica, iar apoi divizăm textul în cuvinte. Luăm fiecare cuvânt în parte și verificăm dacă este un stopword, iar dacă nu este îl adaugăm în mulțimea de cuvinte care urmează să fie returnată.
  Aplicăm funcția de procesare peste toate datele noastre. Urmează să împărțim datele de antrenare în: 20% date de test, 15% date de validare, iar restul, date de antrenare.
  Amestecăm datele pentru că există șanse ca datele să fie într-o ordine care nu reflectă realitatea. De exemplu, se poate ca datele să fie ordonate după etichete, iar atunci programul s-ar antrena pe rând cu câte o limbă.
  Folosim CounterVectorizer pentru a transforma textul într-un vector bazat pe frecvența primelor 37000 cele mai des întâlnite cuvinte, iar apoi, folosim LinearSVC pentru a găsi cel mai bun hiperplan pentru a maximiza marginea, distanta dintre hiperplan si vectorul suport. Antrenarea modelului durează aproximativ 41.34 secunde. Pe Kaggle am obtinut o performanta de 0.674.
